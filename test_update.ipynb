{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지원사업공고 update (추가, 수정, 삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from getpass import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.get_text import get_hwp_text, get_pdf_text, get_image_text # pdf, hwp, png에서 텍스트를 추출하는 사용자 지정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 기존에 저장되어있는 지원사업 공고 파일 및 지난 공고를 불러옴\n",
    "# with open('data/bizinfo.json', 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# with open('data/bizold.json', 'r', encoding='utf-8') as f:\n",
    "#     old_infos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, value in data.items():\n",
    "#     print(f'{len(value)}')\n",
    "\n",
    "# for _, value in old_infos.items():\n",
    "#     print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이트 접속 차단을 받지 않기 위한 header 지정\n",
    "header = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 기업마당의 해시코드를 저장해놓은 dictionary\n",
    "hashcode_dict = {'01':'금융',\n",
    "                '02':'기술',\n",
    "                '03':'인력',\n",
    "                '07':'수출',\n",
    "                '08':'내수',\n",
    "                '09':'창업',\n",
    "                '10':'경영',\n",
    "                '12':'기타'}\n",
    "\n",
    "# key-value를 반대로 저장\n",
    "reverse_dict = {value: key for key, value in hashcode_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(URL, header=header):\n",
    "    '''지원사업 공고에 있는 파일을 다운로드하는 함수'''\n",
    "    # bs4로 해당 URL의 html 구조 파싱\n",
    "    response = requests.get(URL, headers=header)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 파일의 정보를 담을 빈 딕셔너리 선언\n",
    "    file_info = {}\n",
    "\n",
    "    # 다운로드 파일 링크를 담을 빈 리스트 / 파일명을 담을 빈 문자열 선언\n",
    "    down_link, down_title = [], ''\n",
    "\n",
    "    # '본문출력파일'의 파일만 다운로드 하도록 수행하는 반복문 + 조건문\n",
    "    for idx in range(len(soup.select('div.attached_file_list h3'))):\n",
    "        if soup.select('div.attached_file_list h3')[idx].text == '본문출력파일':\n",
    "            down_link = soup.select('div.attached_file_list div.right_btn')[-1].select('a')\n",
    "            file_path = soup.select_one('div.category span').text.strip()\n",
    "\n",
    "            # 다운 받을 공고문 파일의 이름을 공고문의 title로 바꿔서 정리\n",
    "            file_title = soup.select_one('h2.title').text.strip()\n",
    "            file_type = soup.select('div.attached_file_list div.file_name')[-1].text.strip().split('.')[-1]\n",
    "            down_title = file_title + '.' + file_type\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # 다운로드 파일링크는 내부 url이기 때문에 앞에 도메인 주소를 붙여줘야 함.\n",
    "    base_url = 'https://www.bizinfo.go.kr'\n",
    "    down_url = base_url + down_link[1].attrs['href']\n",
    "    \n",
    "\n",
    "    # 다운로드된 파일을 저장할 파일 경로\n",
    "    save_path = f'C:/Users/every/Desktop/Project/team_project/SeSAC_Final/AI-for-Creating-Business-Plan-Drafts/{file_path}/{down_title}'\n",
    "\n",
    "    # HTTP 요청을 보내 파일 다운로드\n",
    "    response = requests.get(down_url, stream=True)\n",
    "    try:\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(1024):  # 1024바이트씩 저장\n",
    "                file.write(chunk)\n",
    "    except:\n",
    "        print(f\"파일 다운로드 실패. 상태 코드: {response.status_code}\")\n",
    "        print(f\"다운로드 실패한 공고 명 : {down_title}\")\n",
    "\n",
    "\n",
    "    # 파일의 정보를 딕셔너리 형태로 담음\n",
    "    # 프레임으로 관리 및 공고 수정 사항을 빠르게 탐색하기 위한 정보 모음집\n",
    "    file_info['지원사업 공고명'] = file_title\n",
    "    file_info['소관부처·지자체'] = soup.select('div.view_cont li div.txt')[0].text.strip()\n",
    "    file_info['사업수행기관'] = soup.select('div.view_cont li div.txt')[1].text.strip()\n",
    "    file_info['신청기간'] = soup.select('div.view_cont li div.txt')[2].text.strip().replace(\"\\r\", \" \").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    file_info['공고파일명'] = file_path + '/' + down_title\n",
    "\n",
    "    return file_info, file_path\n",
    "\n",
    "def fetch_links(hashcode, header=header):\n",
    "    '''기업마당의 메인에 있는 공고 각각의 URL을 리스트로 반환'''\n",
    "\n",
    "    # 기업마당의 공고 URL은 BASE_URL + td class='txt_l a'의 형식으로 되어 있음\n",
    "    BASE_URL = 'https://www.bizinfo.go.kr/web/lay1/bbs/S1T122C128/AS/74/'\n",
    "    idx = 1         # 페이지를 넘기기 위한 인덱스\n",
    "    links = []      # 링크를 정리해둘 리스트 선언\n",
    "\n",
    "    # 공고가 없는 페이지가 나올 때까지 반복문\n",
    "    while True:\n",
    "        URL = f'https://www.bizinfo.go.kr/web/lay1/bbs/S1T122C128/AS/74/list.do?hashCode={hashcode}&cpage={idx}'\n",
    "        response = requests.get(URL, headers=header)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 공고가 없는 페이지가 나올 시 반복문 탈출\n",
    "        if len(soup.select('div.sub_cont tr')) == 2:\n",
    "            break\n",
    "        \n",
    "        # links에 URL 저장\n",
    "        # 해당 페이지에 있는 전체 URL에 대하여 실행\n",
    "        links += [BASE_URL + link.attrs['href'] for link in soup.select('td.txt_l a')]\n",
    "\n",
    "        # 페이지 넘김\n",
    "        idx += 1\n",
    "\n",
    "    return links\n",
    "\n",
    "def update_fetch_links(hashcode, header=header):\n",
    "    '''기업마당의 메인에 있는 공고 각각의 URL을 리스트로 반환'''\n",
    "\n",
    "    # 기업마당의 공고 URL은 BASE_URL + td class='txt_l a'의 형식으로 되어 있음\n",
    "    BASE_URL = 'https://www.bizinfo.go.kr/web/lay1/bbs/S1T122C128/AS/74/'\n",
    "    idx = 1         # 페이지를 넘기기 위한 인덱스\n",
    "    links, titles = [], []     # 링크를 정리해둘 리스트 선언\n",
    "\n",
    "    # 공고가 없는 페이지가 나올 때까지 반복문\n",
    "    while True:\n",
    "        URL = f'https://www.bizinfo.go.kr/web/lay1/bbs/S1T122C128/AS/74/list.do?hashCode={hashcode}&cpage={idx}'\n",
    "        response = requests.get(URL, headers=header)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 공고가 없는 페이지가 나올 시 반복문 탈출\n",
    "        if len(soup.select('div.sub_cont tr')) == 2:\n",
    "            break\n",
    "        \n",
    "        # links에 URL 저장\n",
    "        # 해당 페이지에 있는 전체 URL에 대하여 실행\n",
    "        links += [BASE_URL + link.attrs['href'] for link in soup.select('td.txt_l a')]\n",
    "        titles += [title.text.strip() for title in soup.select('td.txt_l a')]\n",
    "\n",
    "        # 페이지 넘김\n",
    "        idx += 1\n",
    "\n",
    "    return links, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오늘 날짜 가져오기\n",
    "# today = datetime.today().date()        # 현재 날짜 (YYYY-MM-DD) # 실험상 임의로 오늘의 날짜를 1일 뒤로 지정\n",
    "\n",
    "# # 마감기한이 끝났거나 혹은 기한이 저장되어 있지 않은 공고의 삭제\n",
    "# for key, value in tqdm(list(data.items())):  # 딕셔너리 항목을 리스트로 변환하여 순회 (수정 가능하게)\n",
    "\n",
    "#     links, titles = update_fetch_links(reverse_dict[key])  # 기존의 DB와 비교할 오늘의 공고 목록\n",
    "#     now_titles = [] # 현재 DB에 있는 항목을 저장할 리스트\n",
    "\n",
    "#     expired_items = []  # 삭제할 항목을 저장할 리스트\n",
    "    \n",
    "#     for idx in value[:]:  # 원본 리스트를 복사하여 순회\n",
    "\n",
    "#         now_titles.append(idx['지원사업 공고명']) # 현재 공고의 타이틀을 저장\n",
    "\n",
    "#         if idx['신청기간'][0] == '2':  # 마감 기한이 숫자로 시작하는 경우\n",
    "#             deadline = datetime.strptime(idx['신청기간'][-10:], \"%Y.%m.%d\").date()\n",
    "#             if deadline < today:  # 마감 기한이 현재 날짜보다 이전이라면\n",
    "#                 old_infos[key].append(idx)  # 기존 정보 저장\n",
    "#                 expired_items.append(idx)  # 삭제할 항목 저장\n",
    "    \n",
    "\n",
    "#         else:  # 마감 기한이 날짜가 아닌 경우 (예산 소진시까지, 추후 공지, 상시 접수 등)\n",
    "#             if idx['지원사업 공고명'] not in titles:\n",
    "#                 old_infos[key].append(idx)  # 기존 정보 저장\n",
    "#                 expired_items.append(idx)  # 삭제할 항목 저장\n",
    "\n",
    "        \n",
    "#     # 만료된 항목을 기존 리스트에서 제거\n",
    "#     for item in expired_items:\n",
    "#         value.remove(item)\n",
    "    \n",
    "#     # 만약 해당 key의 리스트가 비었다면, 아예 삭제\n",
    "#     if not value:\n",
    "#         del data[key]\n",
    "\n",
    "#     # 새로운 항목에 대하여 기존 딕셔너리에 저장\n",
    "#     for i in range(len(titles)):\n",
    "#         if titles[i] not in now_titles:\n",
    "#             print(titles[i])\n",
    "#             file_info, file_path = download_file(links[i])\n",
    "#             data[file_path].append(file_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, value in data.items():\n",
    "#     print(len(value))\n",
    "\n",
    "# for _, value in old_infos.items():\n",
    "#     print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/bizinfo.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# with open('data/bizold.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(old_infos, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 금융에 대해서만 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 저장되어있는 지원사업 공고 파일 및 지난 공고를 불러옴\n",
    "with open('data/bizinfo_2.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open('data/bizold_2.json', 'r', encoding='utf-8') as f:\n",
    "    old_infos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전날 금융의 공고 개수 : 166, 지난 공고의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "# 개수 확인용 출력\n",
    "print(f'전날 금융의 공고 개수 : {len(data['금융'])}, 지난 공고의 개수 : {len(old_infos['금융'])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:11<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 오늘 날짜 가져오기\n",
    "today = datetime.today().date()        # 현재 날짜 (YYYY-MM-DD) # 실험상 임의로 오늘의 날짜를 1일 뒤로 지정\n",
    "\n",
    "# 마감기한이 끝났거나 혹은 기한이 저장되어 있지 않은 공고의 삭제\n",
    "for key, value in tqdm(list(data.items())):  # 딕셔너리 항목을 리스트로 변환하여 순회 (수정 가능하게)\n",
    "\n",
    "    links, titles = update_fetch_links(reverse_dict[key])  # 기존의 DB와 비교할 오늘의 공고 목록\n",
    "    now_titles = [] # 현재 DB에 있는 항목을 저장할 리스트\n",
    "\n",
    "    expired_items = []  # 삭제할 항목을 저장할 리스트\n",
    "    \n",
    "    for idx in value[:]:  # 원본 리스트를 복사하여 순회\n",
    "\n",
    "        now_titles.append(idx['지원사업 공고명']) # 현재 공고의 타이틀을 저장\n",
    "\n",
    "        if idx['신청기간'][0] == '2':  # 마감 기한이 숫자로 시작하는 경우\n",
    "            deadline = datetime.strptime(idx['신청기간'][-10:], \"%Y.%m.%d\").date()\n",
    "            if deadline < today:  # 마감 기한이 현재 날짜보다 이전이라면\n",
    "                old_infos[key].append(idx)  # 기존 정보 저장\n",
    "                expired_items.append(idx)  # 삭제할 항목 저장\n",
    "    \n",
    "\n",
    "        else:  # 마감 기한이 날짜가 아닌 경우 (예산 소진시까지, 추후 공지, 상시 접수 등)\n",
    "            if idx['지원사업 공고명'] not in titles:\n",
    "                old_infos[key].append(idx)  # 기존 정보 저장\n",
    "                expired_items.append(idx)  # 삭제할 항목 저장\n",
    "\n",
    "        \n",
    "    # 만료된 항목을 기존 리스트에서 제거\n",
    "    for item in expired_items:\n",
    "        value.remove(item)\n",
    "    \n",
    "    # 만약 해당 key의 리스트가 비었다면, 아예 삭제\n",
    "    if not value:\n",
    "        del data[key]\n",
    "\n",
    "    # 새로운 항목에 대하여 기존 딕셔너리에 저장\n",
    "    for i in range(len(titles)):\n",
    "        if titles[i] not in now_titles:\n",
    "            print(titles[i])\n",
    "            file_info, file_path = download_file(links[i])\n",
    "            data[file_path].append(file_info)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전날 금융의 공고 개수 : 166, 지난 공고의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "# 개수 확인용 출력\n",
    "print(f'전날 금융의 공고 개수 : {len(data['금융'])}, 지난 공고의 개수 : {len(old_infos['금융'])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bizinfo_2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open('data/bizold_2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(old_infos, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
